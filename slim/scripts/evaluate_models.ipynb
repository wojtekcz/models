{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib2 import *\n",
    "import os\n",
    "import shutil as sh\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/workspace/models/slim\")\n",
    "\n",
    "from eval_image_classifier import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for all/chosen folders\n",
    "# for all/chosen checkpoints in a folder\n",
    "# use ckpt file\n",
    "# from eval_image_classifier import ???\n",
    "# run it for one checkpoint, one training or list of trainings\n",
    "\n",
    "# get_list_of_training_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_list_of_checkpoints_for_training(train_log_path):\n",
    "    items = list(train_log_path.iterdir())\n",
    "\n",
    "    # filter ckpt out\n",
    "    ckpts = filter(lambda item: 'ckpt' in item.name, items)\n",
    "\n",
    "    # filter index out\n",
    "    ckpts = filter(lambda item: 'index' in item.suffix, items)\n",
    "\n",
    "    # get number ... .ckpt-n. ..., cut 'ckpt-' out\n",
    "    def ckpt_num(name):\n",
    "        name = name.split('.',2)[1]\n",
    "        ckpt_num = int(name.split('-',2)[1])\n",
    "        return ckpt_num\n",
    "\n",
    "    # create list of checkpoint numbers, sort it\n",
    "    ckpt_nums = sorted(map(lambda item: ckpt_num(item.name), ckpts))\n",
    "    ckpt_nums\n",
    "\n",
    "    # map it into \"model.ckpt-n\"\n",
    "    ckpts = map(lambda num: 'model.ckpt-{}'.format(num), ckpt_nums)\n",
    "    return ckpts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# one 1_flowers3 checkpoint \n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "BASE_DIR = Path('/workspace')\n",
    "RUN = '1_flowers3'\n",
    "\n",
    "# Where the training (fine-tuned) checkpoint and logs will be saved to.\n",
    "TRAIN_DIR = BASE_DIR / 'train_logs' / RUN\n",
    "\n",
    "# Where the dataset is saved to.\n",
    "DATASET_DIR = BASE_DIR / 'data/flowers3'\n",
    "\n",
    "EVAL_DIR = BASE_DIR / 'evaluation/evaluation_logs' / RUN\n",
    "\n",
    "checkpoint_name = 'model.ckpt-0'\n",
    "\n",
    "FLAGS.dataset_dir        = str(DATASET_DIR)\n",
    "FLAGS.checkpoint_path    = str(TRAIN_DIR / checkpoint_name)\n",
    "FLAGS.eval_dir           = str(EVAL_DIR)\n",
    "FLAGS.dataset_name       = 'flowers'\n",
    "FLAGS.dataset_split_name = 'validation'\n",
    "FLAGS.model_name         = 'inception_v3'\n",
    "\n",
    "log_dir = FLAGS.eval_dir\n",
    "\n",
    "# tf.gfile.DeleteRecursively(log_dir);\n",
    "# tf.gfile.MakeDirs(log_dir)\n",
    "\n",
    "main(FLAGS)\n",
    "# tf.app.run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def evaluate_checkpoint(train_dir, dataset_dir, eval_dir, checkpoint_name, dataset_name, dataset_split_name, model_name):\n",
    "\n",
    "    FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "    FLAGS.dataset_dir        = str(dataset_dir)\n",
    "    FLAGS.checkpoint_path    = str(train_dir / checkpoint_name)\n",
    "    FLAGS.eval_dir           = str(eval_dir)\n",
    "    FLAGS.dataset_name       = dataset_name\n",
    "    FLAGS.dataset_split_name = dataset_split_name\n",
    "    FLAGS.model_name         = model_name\n",
    "\n",
    "    main(FLAGS)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# 1_flowers3\n",
    "\n",
    "train_logs_path = Path('../train_logs');\n",
    "# train_log_path = train_logs_path / '1_flowers3'\n",
    "train_log_path = train_logs_path / '3_car-reco3_inception_v3'\n",
    "\n",
    "checkpoints = get_list_of_checkpoints_for_training(train_log_path)\n",
    "\n",
    "for checkpoint_name in checkpoints:\n",
    "    BASE_DIR = Path('/workspace')\n",
    "#     RUN = '1_flowers3'\n",
    "    RUN = '3_car-reco3_inception_v3'\n",
    "\n",
    "    # Where the training (fine-tuned) checkpoint and logs will be saved to.\n",
    "    TRAIN_DIR = BASE_DIR / 'train_logs' / RUN\n",
    "#     DATASET_DIR = BASE_DIR / 'data/flowers3'\n",
    "    DATASET_DIR = BASE_DIR / 'data/car-reco3'\n",
    "\n",
    "    EVAL_DIR = BASE_DIR / 'evaluation/evaluation_logs' / RUN\n",
    "#     dataset_name = 'flowers'\n",
    "    dataset_name = 'cars'\n",
    "    dataset_split_name = 'validation'\n",
    "    model_name = 'inception_v3'\n",
    "    print(checkpoint_name)\n",
    "    print(EVAL_DIR)\n",
    "    evaluate_checkpoint(TRAIN_DIR, DATASET_DIR, EVAL_DIR, checkpoint_name, dataset_name, dataset_split_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "\n",
    "# RUN = '2_car-reco3_inception_v3-mac'\n",
    "# model_name = 'inception_v3'\n",
    "\n",
    "# RUN = '3_car-reco3_inception_v3'\n",
    "# model_name = 'inception_v3'\n",
    "\n",
    "# RUN = '4_car-reco3_inception_resnet_v2'\n",
    "# model_name = 'inception_resnet_v2'\n",
    "\n",
    "# RUN = '5_car-reco3_inception_v4'\n",
    "# model_name = 'inception_v4'\n",
    "\n",
    "# RUN = '6_car-reco3_resnet_v2_152'\n",
    "# model_name = 'resnet_v2_152'\n",
    "\n",
    "# RUN = '7_car-reco3_resnet_v2'\n",
    "# model_name = 'resnet_v1_152'\n",
    "\n",
    "# RUN = '8_car-reco3_inception_v3'\n",
    "# model_name = 'inception_v3'\n",
    "\n",
    "RUN = '9_car-reco3-70_inception_v3'\n",
    "model_name = 'inception_v3'\n",
    "\n",
    "\n",
    "BASE_DIR = Path('/workspace')\n",
    "TRAIN_DIR = BASE_DIR / 'train_logs' / RUN\n",
    "EVAL_DIR = TRAIN_DIR / 'eval'\n",
    "\n",
    "DATASET_DIR = BASE_DIR / 'data' / 'car-reco3-70'\n",
    "dataset_name = 'cars'\n",
    "# dataset_split_name = 'train'\n",
    "dataset_split_name = 'validation'\n",
    "\n",
    "\n",
    "tf.gfile.MakeDirs(str(EVAL_DIR))\n",
    "\n",
    "\n",
    "print(DATASET_DIR);\n",
    "print(EVAL_DIR);\n",
    "\n",
    "\n",
    "checkpoints = get_list_of_checkpoints_for_training(TRAIN_DIR)\n",
    "# checkpoints = [get_list_of_checkpoints_for_training(TRAIN_DIR)[0]] # first checkpoint only\n",
    "\n",
    "\n",
    "for checkpoint_name in checkpoints:\n",
    "    print(checkpoint_name)\n",
    "    print(EVAL_DIR)    \n",
    "\n",
    "    FLAGS.dataset_dir        = str(DATASET_DIR)\n",
    "    FLAGS.checkpoint_path    = str(TRAIN_DIR / checkpoint_name)\n",
    "    FLAGS.eval_dir           = str(EVAL_DIR)\n",
    "    FLAGS.dataset_name       = dataset_name\n",
    "    FLAGS.dataset_split_name = dataset_split_name\n",
    "    FLAGS.model_name         = model_name\n",
    "    FLAGS.max_num_batches    = 4\n",
    "    #FLAGS.labels_offset      = 1\n",
    "\n",
    "    main(FLAGS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
