{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pathlib2 import *\n",
    "from pathlib import *\n",
    "import json\n",
    "\n",
    "import os\n",
    "import shutil as sh\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/workspace/models/slim\")\n",
    "# sys.path.insert(0, \"/Users/wcz/Beanflows/All_Beans/Machine_Learning/innovavant-Training-Car-Recognition-Model/choose-network-architecture/models/slim\")\n",
    "\n",
    "\n",
    "from eval_image_classifier import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# for all/chosen folders\n",
    "# for all/chosen checkpoints in a folder\n",
    "# use ckpt file\n",
    "# from eval_image_classifier import ???\n",
    "# run it for one checkpoint, one training or list of trainings\n",
    "\n",
    "# get_list_of_training_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "def get_list_of_checkpoints_for_training(train_log_path):\n",
    "    items = list(train_log_path.iterdir())\n",
    "\n",
    "    # filter ckpt out\n",
    "    ckpts = filter(lambda item: 'ckpt' in item.name, items)\n",
    "\n",
    "    # filter index out\n",
    "    ckpts = filter(lambda item: 'index' in item.suffix, items)\n",
    "\n",
    "    # get number ... .ckpt-n. ..., cut 'ckpt-' out\n",
    "    def ckpt_num(name):\n",
    "        name = name.split('.',2)[1]\n",
    "        ckpt_num = int(name.split('-',2)[1])\n",
    "        return ckpt_num\n",
    "\n",
    "    # create list of checkpoint numbers, sort it\n",
    "    ckpt_nums = sorted(map(lambda item: ckpt_num(item.name), ckpts))\n",
    "    return ckpt_nums\n",
    "\n",
    "    # map it into \"model.ckpt-n\"\n",
    "#     ckpts = map(lambda num: 'model.ckpt-{}'.format(num), ckpt_nums)\n",
    "#     return ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "last_eval_checkpoint_key = 'last_eval_checkpoint'\n",
    "\n",
    "def load_last_eval_checkpoint(EVAL_DIR):\n",
    "    fn = str(EVAL_DIR / last_eval_checkpoint_key)\n",
    "\n",
    "    try:\n",
    "        with open(fn, 'r') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "            # if the file is empty the ValueError will be thrown\n",
    "            except ValueError:\n",
    "               data = {last_eval_checkpoint_key : -1}\n",
    "    except IOError: # python 2\n",
    "#     except FileNotFoundError: # python 3\n",
    "               data = {last_eval_checkpoint_key : -1}\n",
    "\n",
    "        \n",
    "    return data[last_eval_checkpoint_key]\n",
    "\n",
    "def save_last_eval_checkpoint(EVAL_DIR, last_eval_checkpoint):\n",
    "    fn = str(EVAL_DIR / last_eval_checkpoint_key)\n",
    "    json.dump({last_eval_checkpoint_key : last_eval_checkpoint}, open(fn,'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# RUN = '2_car-reco3_inception_v3-mac' # model_name = 'inception_v3'\n",
    "# RUN = '3_car-reco3_inception_v3' # model_name = 'inception_v3'\n",
    "# RUN = '4_car-reco3_inception_resnet_v2' # model_name = 'inception_resnet_v2'\n",
    "# RUN = '5_car-reco3_inception_v4' # model_name = 'inception_v4'\n",
    "# RUN = '6_car-reco3_resnet_v2_152' # model_name = 'resnet_v2_152'\n",
    "# RUN = '7_car-reco3_resnet_v2' # model_name = 'resnet_v1_152'\n",
    "# RUN = '8_car-reco3_inception_v3' # model_name = 'inception_v3'\n",
    "# -----------------------------------------------\n",
    "# RUN = '9_car-reco3-70_inception_v3' # model_name = 'inception_v3'\n",
    "# RUN = '10_car-reco3-70_inception_v4' # model_name = 'inception_v4'\n",
    "# RUN = '11_car-reco3-70_inception_resnet_v2' # model_name = 'inception_resnet_v2'\n",
    "# RUN = '13_car-reco3-70_inception_resnet_v2' # model_name = 'inception_resnet_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# RUN = '12_car-reco3-70_resnet_v2_152'\n",
    "# model_name = 'resnet_v2_152'\n",
    "\n",
    "# RUN = '15_car-reco3-70_resnet_v2_152'\n",
    "# model_name = 'resnet_v2_152'\n",
    "\n",
    "# RUN = '16_comp_cars_resnet_v2_152'\n",
    "# model_name = 'resnet_v2_152'\n",
    "\n",
    "RUN = '17_car-reco3-70_resnet_v2_152'\n",
    "model_name = 'resnet_v2_152'\n",
    "\n",
    "\n",
    "\n",
    "# max_num_batches    = 10 # 10 # 43 # 435\n",
    "max_num_batches    = 179 # 4 # 50 # 179\n",
    "BASE_DIR           = Path('/workspace')\n",
    "# BASE_DIR           = Path('/Users/wcz/Beanflows/All_Beans/Machine_Learning/innovavant-Training-Car-Recognition-Model/choose-network-architecture')\n",
    "TRAIN_DIR          = BASE_DIR / 'big_storage/all_train_logs' / RUN\n",
    "EVAL_DIR           = TRAIN_DIR / 'eval-{}'.format(max_num_batches)\n",
    "DATASET_DIR        = BASE_DIR / 'data' / 'car-reco3-70'\n",
    "# DATASET_DIR        = BASE_DIR / 'data' / 'comp_cars'\n",
    "dataset_name       = 'car_reco3_70'\n",
    "# dataset_name       = 'comp_cars'\n",
    "\n",
    "# dataset_split_name = 'train'\n",
    "dataset_split_name = 'validation'\n",
    "\n",
    "tf.gfile.MakeDirs(str(EVAL_DIR))\n",
    "\n",
    "print(EVAL_DIR);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_ckpt_nums = get_list_of_checkpoints_for_training(TRAIN_DIR)\n",
    "ckpt_count = len(all_ckpt_nums)\n",
    "print ('ckpt_count: ', ckpt_count)\n",
    "\n",
    "last_eval_checkpoint = load_last_eval_checkpoint(EVAL_DIR)\n",
    "# get checkpoint numbers bigger than last_checkpoint_number\n",
    "ckpt_nums = list(filter(lambda x: x > last_eval_checkpoint, all_ckpt_nums))\n",
    "ckpt_nums = [all_ckpt_nums[-1]]\n",
    "\n",
    "print('all_ckpt_nums: ', all_ckpt_nums)\n",
    "print('last_eval_checkpoint: ', last_eval_checkpoint)\n",
    "print('ckpt_nums: ', ckpt_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpoints = map(lambda num: 'model.ckpt-{}'.format(num), ckpt_nums)\n",
    "\n",
    "FLAGS.eval_dir           = str(EVAL_DIR)\n",
    "FLAGS.dataset_name       = dataset_name\n",
    "FLAGS.dataset_split_name = dataset_split_name\n",
    "FLAGS.model_name         = model_name\n",
    "FLAGS.max_num_batches    = max_num_batches\n",
    "\n",
    "for ckpt_num in ckpt_nums:\n",
    "    checkpoint_name = 'model.ckpt-{}'.format(ckpt_num)\n",
    "    FLAGS.dataset_dir        = str(DATASET_DIR)\n",
    "    FLAGS.checkpoint_path    = str(TRAIN_DIR / checkpoint_name)\n",
    "    print(FLAGS.checkpoint_path)\n",
    "    #FLAGS.labels_offset      = 1\n",
    "    main(FLAGS)\n",
    "    save_last_eval_checkpoint(EVAL_DIR, ckpt_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
